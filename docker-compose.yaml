version: '3.8'

services:
  kafka:
    image: bitnami/kafka:3.4
    container_name: kafka
    volumes:
      - /home/mario.gutierrezd/init.sh:/scripts/init.sh
    ports:
      - "9092:9092"
    networks:
      - red-ibdn
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_LOG_DIRS=/bitnami/kafka/data
    command: "bash /scripts/init.sh"

  mongo:
    image: mario11gd/mongo-image
    container_name: mongo
    ports:
      - "27017:27017"
    networks:
      - red-ibdn
    volumes:
      - mongo-data:/data/db

  spark-master:
    image: bde2020/spark-master:3.2.1-hadoop3.2
    container_name: spark-master
    ports:
      - "7077:7077"
      - "9001:9001"
      - "8080:8080"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - "INIT_DAEMON_STEP=setup_spark"
      - "constraint:node==spark-master"
    networks:
      - red-ibdn
    volumes:
      - ./practica_creativa:/practica_creativa

  spark-worker-1:
    image: bde2020/spark-worker:3.2.1-hadoop3.2
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - "INIT_DAEMON_STEP=setup_spark"
      - "constraint:node==spark-worker"
    networks:
      - red-ibdn
    volumes:
      - ./practica_creativa:/practica_creativa

  spark-worker-2:
    image: bde2020/spark-worker:3.2.1-hadoop3.2
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - "constraint:node==spark-worker"
    networks:
      - red-ibdn
    volumes:
      - ./practica_creativa:/practica_creativa

  spark-submit:
    image: bde2020/spark-submit:3.2.1-hadoop3.2
    container_name: spark-submit
    depends_on:
      - spark-master
      - spark-worker-1
      - spark-worker-2
      - airflow
    ports:
      - "4040:4040"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - "constraint:node==spark-master"
    networks:
      - red-ibdn
    stdin_open: true  
    tty: true
    command: bash -i /practica_creativa/wait_for_airflow_and_submit.sh
    volumes:
      - ./practica_creativa:/practica_creativa
 
  flask:
    image: mario11gd/flask-image
    container_name: flask
    networks:
      - red-ibdn
    ports:
      - 5001:5001
    environment:
      - PROJECT_HOME=/app

  nifi:
    image: apache/nifi:1.23.2
    container_name: nifi
    ports:
      - "8520:8520"
    networks:
      - red-ibdn
    environment:
      - NIFI_WEB_HTTP_PORT=8520
      - SINGLE_USER_CREDENTIALS_USERNAME=admin
      - SINGLE_USER_CREDENTIALS_PASSWORD=admin123
    volumes:
      - ./nifi-output:/opt/nifi/output

  hadoop-namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-namenode
    environment:
      - CLUSTER_NAME=example1
      - INIT_DAEMON_STEP=setup_hdfs
      - HDFS_CONF_dfs_webhdfs_enabled=true
      - HDFS_CONF_dfs_permissions_enabled=false
      - HDFS_CONF_dfs_disk_balancer_enabled=false
    ports:
      - "9870:9870"  
      - "8020:8020"  
    volumes:
      - hadoop-namenode:/hadoop/dfs/name
    networks:
      - red-ibdn

  hadoop-datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-datanode
    environment:
      - HDFS_CONF_dfs_webhdfs_enabled=true
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode:8020
    volumes:
      - hadoop-datanode:/hadoop/dfs/data
    depends_on:
      - hadoop-namenode
    networks:
      - red-ibdn

  airflow:
    image: alejandrotapiamartinez/airflow-image
    container_name: airflow
    networks:
      - red-ibdn
    ports:
      - "8181:8181"
    environment:
      - AIRFLOW_HOME=/airflow
    volumes:
      - ./practica_creativa:/practica_creativa
      - ./practica_creativa/models:/models
    command: bash -c "\
      airflow db init && \
      airflow users create --username admin --firstname Mario --lastname Tapia --role Admin --email example@mail.org --password admin && \
      supervisord"


networks:
  red-ibdn:
    driver: bridge

volumes:
  mongo-data:
  hadoop-namenode:
  hadoop-datanode: 